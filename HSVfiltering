import numpy as np
import pandas as pd
import cv2
from sklearn.cluster import KMeans
from scipy.optimize import linear_sum_assignment
from scipy.spatial.distance import cdist
import tracktor as tr
import cv2
import sys
from matplotlib import pyplot as plt





df_params = pd.read_csv("params.csv")
num_rows = df_params.shape[0]
for i in range(0, num_rows):
    print(f"min_area is {df_params.iloc[i]['min_area']} max_area is {df_params.iloc[i]['max_area']} bock_size is {df_params.iloc[i]['block_size']} and offset is {df_params.iloc[i]['offset']}")








# colours is a vector of BGR values which are used to identify individuals in the video
# t_id is termite id and is also used for individual identification
# number of elements in colours should be greater than n_inds (THIS IS NECESSARY FOR VISUALISATION ONLY)
# number of elements in t_id should be greater than n_inds (THIS IS NECESSARY TO GET INDIVIDUAL-SPECIFIC DATA)
n_inds = 1
t_id = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']
colours = [(0,0,255),(0,255,255),(255,0,255),(255,255,255),(255,255,0),(255,0,0),(0,255,0),(0,0,0)]

# this is the block_size and offset used for adaptive thresholding (block_size should always be odd)
# these values are critical for tracking performance
block_size = 51
offset = 25

# the scaling parameter can be used to speed up tracking if video resolution is too high (use value 0-1)
scaling = 1.0

# minimum area and maximum area occupied by the animal in number of pixels
# this parameter is used to get rid of other objects in view that might be hard to threshold out but are differently sized
min_area = 0
max_area = 200

# mot determines whether the tracker is being used in noisyconditions to track a single object or for multi-object
# using this will enable k-means clustering to force n_inds number of animals
mot = False

# name of source video and paths
video = 'resize3'
input_vidpath = 'C:/Users/aryan/Downloads/tracktor-master/videos/' + video + '.mp4'
output_vidpath = 'C:/Users/aryan/Downloads/tracktor-master/output/' + video + '_tracked.mp4'
output_filepath = 'C:/Users/aryan/Downloads/tracktor-master/output/' + video + '_tracked.csv'
codec = 'DIVX' # try other codecs if the default doesn't work ('DIVX', 'avc1', 'XVID') note: this list is non-exhaustive










def get_countours_bounds(contours):
    bounds_list = []
    contours_list = [[list(c[0]) for c in cc] for cc in contours]
    for i in range(len(contours_list)):
        min_xy = tuple(np.min(np.asarray(contours_list[i]), axis=0))
        max_xy = tuple(np.max(np.asarray(contours_list[i]), axis=0))
        bounds_list.append([min_xy, max_xy])

    return bounds_list






mouseX, mouseY = (-1, -1)

def mouse_left_click(event, x, y, flags, param):
    global mouseX, mouseY
    img_window_name = param["img_window_name"]
    if event == cv2.EVENT_LBUTTONUP:
        (img_x, img_y, img_w, img_h) = cv2.getWindowImageRect(img_window_name)
        mouseX, mouseY = x, y
        print(mouseX, mouseY)


def show_first_image(img, side_length):
    global mouseX, mouseY
    img_window_name = 'Starting Image'
    cv2.namedWindow(img_window_name)
    cv2.setMouseCallback(img_window_name, mouse_left_click, param={"img_window_name": img_window_name})
    print("Click on the image to choose coordinates for a shark.\nWhen done, press the 'Esc' key.")
    while(True):
        cv2.imshow(img_window_name, img)
        k = cv2.waitKey(30) & 0xFF
        if k == 27:
            break
        #elif k == ord('a'):
        #    print('"a" key pressed')
        #    #print(mouseX, mouseY)

    cv2.destroyWindow(img_window_name)
    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    print(f"Final coordinates selected: ({mouseX}, {mouseY})\nHSV Color value: {hsv_img[mouseY, mouseX]}")
    return hsv_img[mouseY, mouseX]









def get_HSV():
    cap = cv2.VideoCapture(input_vidpath)
    if cap.isOpened() == False:
        sys.exit('Video file cannot be read! Please check input_vidpath to ensure it is correctly pointing to the video file')
    ret, frame = cap.read()
    if ret == True:
        # Preprocess the image for background subtraction
        frame = cv2.resize(frame, None, fx = scaling, fy = scaling, interpolation = cv2.INTER_LINEAR)

        return(show_first_image(frame, 5))







def detect_and_draw_contours_noHSV(frame, thresh, meas_last, meas_now, min_area = 0, max_area = 10000):
    """
    This function detects contours, thresholds them based on area and draws them.

    Parameters
    ----------
    frame: ndarray, shape(n_rows, n_cols, 3)
        source image containing all three colour channels
    thresh: ndarray, shape(n_rows, n_cols, 1)
        binarised(0,255) image
    meas_last: array_like, dtype=float
        individual's location on previous frame
    meas_now: array_like, dtype=float
        individual's location on current frame
    min_area: int
        minimum area threhold used to detect the object of interest
    max_area: int
        maximum area threhold used to detect the object of interest

    Returns
    -------
    final: ndarray, shape(n_rows, n_cols, 3)
        final output image composed of the input frame with object contours 
        and centroids overlaid on it
    contours: list
        a list of all detected contours that pass the area based threhold criterion
    meas_last: array_like, dtype=float
        individual's location on previous frame
    meas_now: array_like, dtype=float
        individual's location on current frame
    """
    # Detect contours and draw them based on specified area thresholds
    if int(cv2.__version__[0]) == 3:
    	img, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    else:
    	contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    img = cv2.cvtColor(thresh.copy(), cv2.COLOR_GRAY2BGR)

    final = frame.copy()

    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)


    i = 0
    meas_last = meas_now.copy()
    del meas_now[:]
    while i < len(contours):
        mask = np.zeros(hsv_frame.shape[:2], np.uint8)
        cv2.drawContours(mask, [contours[i]], -1, 255, -1)
        mean_mask = np.round(cv2.mean(hsv_frame, mask=mask)).astype(np.uint8)[:3]
        print(mean_mask)

        area = cv2.contourArea(contours[i])


        if area < min_area or area > max_area:
            del contours[i]
        else:
            cv2.drawContours(final, contours, i, (0,0,255), 1)
            M = cv2.moments(contours[i])
            if M['m00'] != 0:
            	cx = M['m10']/M['m00']
            	cy = M['m01']/M['m00']
            else:
            	cx = 0
            	cy = 0
            meas_now.append([cx,cy])
            i += 1
    return final, contours, meas_last, meas_now









def get_HSV_contours():
    cap = cv2.VideoCapture(input_vidpath)
    if cap.isOpened() == False:
        sys.exit('Video file cannot be read! Please check input_vidpath to ensure it is correctly pointing to the video file')
    ret, frame = cap.read()
    if ret == True:
        # Preprocess the image for background subtraction
        frame = cv2.resize(frame, None, fx = scaling, fy = scaling, interpolation = cv2.INTER_LINEAR)
        thresh = tr.colour_to_thresh(frame, block_size, offset)
        grayscale = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)

        meas_last = list(np.zeros((n_inds,2)))
        meas_now = list(np.zeros((n_inds,2)))


        final, contours, meas_last, meas_now = detect_and_draw_contours_noHSV(frame, thresh, meas_last, meas_now, min_area, 4000)

        return(show_first_image(frame, 5))









def HSV_thresholding(img, lower, upper):
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    mask = cv2.inRange(hsv, lower, upper)
    kernel = np.ones((5,5),np.uint8)
    mask = cv2.dilate(mask,kernel,iterations = 3)
    mask = cv2.erode(mask,kernel,iterations = 3)

    output = cv2.bitwise_and(img,img, mask= mask)

    return output
    
    
    
    
    
    








## Open video
cap = cv2.VideoCapture(input_vidpath)
if cap.isOpened() == False:
    sys.exit('Video file cannot be read! Please check input_vidpath to ensure it is correctly pointing to the video file')

## Video writer class to output video with contour and centroid of tracked object(s)
# make sure the frame size matches size of array 'final'
fourcc = cv2.VideoWriter_fourcc(*codec)
output_framesize = (int(cap.read()[1].shape[1]*scaling),int(cap.read()[1].shape[0]*scaling))
out = cv2.VideoWriter(filename = output_vidpath, fourcc = fourcc, fps = 60.0, frameSize = output_framesize, isColor = True)

## Individual location(s) measured in the last and current step
meas_last = list(np.zeros((n_inds,2)))
meas_now = list(np.zeros((n_inds,2)))

df = []
last = 0

frame_bounds_list = []



param_text = f"block_size: {block_size}; offset: {offset}; min_area: {min_area}; max_area: {max_area}"

HSV = get_HSV_contours()

offset = 20
blocksize = 31

while(True): #True
    # Capture frame-by-frame
    ret, frame = cap.read()
    
    print(frame.shape)
    
    this = cap.get(1)
    if ret == True:
        # Preprocess the image for background subtraction
        frame = cv2.resize(frame, None, fx = scaling, fy = scaling, interpolation = cv2.INTER_LINEAR)
        
        
        
        thresh = tr.colour_to_thresh(frame, block_size, offset)
        grayscale = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)
        final, contours, meas_last, meas_now = tr.detect_and_draw_contours(frame, thresh, meas_last, meas_now, HSV, min_area, 4000)
        ''''''
        if len(meas_now) != n_inds:
            contours, meas_now = tr.apply_k_means(contours, n_inds, meas_now)
            
            frame_bounds_list.append(get_countours_bounds(contours))
            
            '''
            contours_list = [[list(c[0]) for c in cc] for cc in contours]
            contour_0 = contours_list[0]
            contour_0_tuples = [tuple(p) for p in contour_0]
            print(contour_0_tuples)
            '''
        
        row_ind, col_ind = tr.hungarian_algorithm(meas_last, meas_now)
        final, meas_now, df = tr.reorder_and_draw(final, colours, n_inds, col_ind, meas_now, df, mot, this)
        
        # add frame number
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(final, param_text, (30,500), font, 1, (255,255,255), 2)
        
        # Create output dataframe
        for i in range(n_inds):
            df.append([this, meas_now[i][0], meas_now[i][1]])
        
        
        plt.hist(frame.ravel(),256,[0,256])
        plt.show()
        
        # Display the resulting frame
        out.write(final)
        cv2.imshow('frame', final)
        if cv2.waitKey(1) == 27:
            break
            
    if last >= this:
        break
    
    last = this
    

## Write positions to file
df = pd.DataFrame(np.matrix(df), columns = ['frame','pos_x','pos_y'])
df.to_csv(output_filepath, sep=',')

## When everything done, release the capture
cap.release()
out.release()
cv2.destroyAllWindows()
cv2.waitKey(1)







import matplotlib.pyplot as plt

tmp = df[df['frame'] < 500]
plt.figure(figsize=(10,10))
plt.scatter(tmp['pos_x'], tmp['pos_y'])
plt.xlabel('pos_x')
plt.ylabel('pos_y')
plt.show()

